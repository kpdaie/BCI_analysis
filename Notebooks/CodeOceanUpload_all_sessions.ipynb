{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90ee6a29-c02d-4b25-808c-c091a0855ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "print(pd. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c560a7f-3313-41a8-8e81-7631d8945702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#import BCI_analysis\n",
    "from pathlib import Path\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde50f0d-2cdf-439a-9af6-58a5bc39a944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing subject id for BCINM_004 ..  skipping\n",
      "starting BCINM_006 - 010324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/bucket/Data/Behavior/BCI_exported/Bergamo-2P-Photostim/BCINM_006/010324-bpod_zaber.npy...\n",
      "- [1 files][  4.5 MiB/  4.5 MiB]                                                \n",
      "Operation completed over 1 objects/4.5 MiB.                                      \n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-104853/20240103-104853.csv...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-104853/__init__.py...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-104853/user_settings.py...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-104853/__pycache__/user_settings.cpython-36.pyc...\n",
      "/ [4/4 files][  7.2 KiB/  7.2 KiB] 100% Done                                    \n",
      "Operation completed over 4 objects/7.2 KiB.                                      \n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113036/20240103-113036.csv...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113036/__init__.py...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113036/user_settings.py...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113036/__pycache__/user_settings.cpython-36.pyc...\n",
      "/ [4/4 files][199.5 KiB/199.5 KiB] 100% Done                                    \n",
      "Operation completed over 4 objects/199.5 KiB.                                    \n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113252/20240103-113252.csv...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113252/__init__.py...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113252/user_settings.py...\n",
      "Copying file:///home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/20240103-113252/__pycache__/user_settings.cpython-36.pyc...\n",
      "/ [4/4 files][  1.5 MiB/  1.5 MiB] 100% Done                                    \n",
      "Operation completed over 4 objects/1.5 MiB.                                      \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asasa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(upload_json_location, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    257\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(r_dict, f)\n\u001b[0;32m--> 258\u001b[0m \u001b[43masasa\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asasa' is not defined"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#import BCI_analysis\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# generate a csv file and collect data in folders if necessary.\n",
    "metadata_dir = '/home/jupyter/bucket/Metadata/' # imports\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#import BCI_analysis\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# generate a csv file and collect data in folders if necessary.\n",
    "metadata_dir = '/home/jupyter/bucket/Metadata/' \n",
    "dlc_base_dir = os.path.abspath(\"/home/jupyter/bucket/Data/Behavior_videos/DLC_output/Bergamo-2P-Photostim/\")\n",
    "bpod_path = os.path.abspath(\"/home/jupyter/bucket/Data/Behavior/BCI_exported/Bergamo-2P-Photostim/\")\n",
    "suite2p_path = os.path.abspath(\"/home/jupyter/bucket/Data/Calcium_imaging/suite2p/Bergamo-2P-Photostim/\")\n",
    "raw_imaging_path = os.path.abspath(\"/home/jupyter/bucket/Data/Calcium_imaging/raw/Bergamo-2P-Photostim/\")\n",
    "\n",
    "sessionwise_data_path = os.path.abspath(\"/home/jupyter/bucket/Data/Calcium_imaging/sessionwise_tba/\")\n",
    "\n",
    "face_rhythm_base_dir = '/home/jupyter/bucket/Data/Behavior_videos/FaceRhythm/'\n",
    "motion_energy_base_dir = os.path.abspath(\"/home/jupyter/bucket/Data/Behavior_videos/MotionEnergy/Bergamo-2P-Photostim/\")\n",
    "raw_video_path = os.path.abspath(\"/home/jupyter/bucket/Data/Behavior_videos/raw/Bergamo-2P-Photostim/\")\n",
    "\n",
    "CO_save_path = \"/home/jupyter/bucket/CodeOcean_transfer/\"\n",
    "\n",
    "sessions_with_errors = [] # sessions that are skipped collected in this list\n",
    "no_cn_sessions = []\n",
    "invalid_neurons = [] # with inf\n",
    "blacklist = []\n",
    "mat_files = []\n",
    "session_dates = {}\n",
    "kept_files = []\n",
    "files_thrown_away = []\n",
    "only_csv_metadata = False\n",
    "version = 1\n",
    "skipped_directories = []\n",
    "skip_reason = []\n",
    "for mouse_id in os.listdir(raw_imaging_path):\n",
    "    \n",
    "    if 'BCI' not in mouse_id:\n",
    "       # print('{} is not a proper subject name, skipping'.format(mouse_id))\n",
    "        skipped_directories.append(os.path.join(raw_imaging_path,mouse_id))\n",
    "        skip_reason.append('improper mouse id')\n",
    "        continue\n",
    "    for session in os.listdir(os.path.join(raw_imaging_path,mouse_id)):\n",
    "        try:\n",
    "            datetime.datetime.strptime(session,'%m%d%y')\n",
    "        except:\n",
    "            #print('{} is not a proper session folder, skipping'.format(session))\n",
    "            skipped_directories.append(os.path.join(raw_imaging_path,mouse_id,session))\n",
    "            skip_reason.append('improper session name')\n",
    "            continue\n",
    "        if mouse_id not in session_dates.keys():\n",
    "            session_dates[mouse_id] = {}\n",
    "        session_dates[mouse_id][datetime.datetime.strptime(session,'%m%d%y')]  = [session]\n",
    "        \n",
    "        \n",
    "        \n",
    "upload_dict = {'platform':[],\n",
    "                'acq_datetime':[],\n",
    "                'subject_id':[],\n",
    "                's3_bucket':[],\n",
    "                'modality0':[],\n",
    "                'modality0.source':[],\n",
    "                'modality1':[],\n",
    "                'modality1.source':[],\n",
    "                'modality2':[],\n",
    "                'modality2.source':[],\n",
    "                'version':[]}\n",
    "#asdsa\n",
    "platform = 'single-plane-ophys'\n",
    "s3_bucket = 'aind-ophys-data'\n",
    "df_metadata=pd.read_csv(os.path.join(metadata_dir,'Surgeries-BCI.csv'))\n",
    "blacklist = ['BCI_29 - 041822',\n",
    "            'BCI_34 - 113022',\n",
    "            'BCI_34 - 120122',\n",
    "            'BCI_34 - 120522'] # should be checked..\n",
    "blacklist = []\n",
    "for mouse_id in list(session_dates.keys()):#[::-1]:\n",
    "    mouseid = mouse_id\n",
    "    while mouseid.find('_')>-1:\n",
    "        mouseid = mouseid[:mouseid.find('_')]+mouseid[mouseid.find('_')+1:]\n",
    "    for session_date in np.sort(list(session_dates[mouse_id].keys())):\n",
    "        [session] = session_dates[mouse_id][session_date]\n",
    "        # load metadata to find subject_id\n",
    "        try:\n",
    "            try:\n",
    "                subject_id = int(df_metadata.loc[df_metadata['ID']==mouse_id,'animal#'].values[0])\n",
    "            except:\n",
    "                subject_id = int(df_metadata.loc[df_metadata['ID']==mouseid,'animal#'].values[0])    \n",
    "        except:\n",
    "            subject_id = None\n",
    "            print('missing subject id for {} ..  skipping'.format(mouse_id))\n",
    "            skipped_directories.append(os.path.join(raw_imaging_path,mouse_id))\n",
    "            skip_reason.append('mouse id number not found')\n",
    "            break\n",
    "        upload_json_location = Path(os.path.join(CO_save_path,'{}-{}'.format(mouse_id,session),'uppload_job_part.json'))\n",
    "        \n",
    "        # load exported bpod data to find acq datetime\n",
    "        behavior_fname = os.path.join(bpod_path,mouse_id, f\"{session}-bpod_zaber.npy\")\n",
    "        try:\n",
    "            bpod_dict = np.load(behavior_fname,allow_pickle = True).tolist()\n",
    "        except:\n",
    "            print('no behavior found, skipping {} - {}'.format(mouse_id,session))\n",
    "            skipped_directories.append(os.path.join(raw_imaging_path,mouse_id,session))\n",
    "            skip_reason.append('no behavior found')\n",
    "            continue\n",
    "        if 'scanimage_tiff_headers' not in bpod_dict.keys():\n",
    "            print('no scanimage header found in behavior file, skipping {} - {}'.format(mouse_id,session))\n",
    "            skip_reason.append('no scanimage header found')\n",
    "            skipped_directories.append(os.path.join(raw_imaging_path,mouse_id,session))\n",
    "            continue\n",
    "            \n",
    "        redo = True\n",
    "        try:\n",
    "            with open(upload_json_location, 'r') as f:\n",
    "                upload_json = json.load(f)\n",
    "            if upload_json['version'] == version:\n",
    "                redo = False\n",
    "        except:\n",
    "            redo = True\n",
    "        if redo == False:\n",
    "            print('already done, same version({}) skipping'.format(version))\n",
    "            continue\n",
    "        if '{} - {}'.format(mouse_id,session) in blacklist:\n",
    "            print('skipping {} - {}: blacklisted'.format(mouse_id,session))\n",
    "            skip_reason.append('blacklisted')\n",
    "            skipped_directories.append(os.path.join(raw_imaging_path,mouse_id,session))\n",
    "            continue\n",
    "        print('starting {} - {}'.format(mouse_id,session))\n",
    "        idx = -1\n",
    "        tiffheader = np.nan\n",
    "        while np.abs(idx)<len(bpod_dict['scanimage_tiff_headers']):\n",
    "            try:\n",
    "                tiffheader = bpod_dict['scanimage_tiff_headers'][idx].tolist()[0]\n",
    "                break\n",
    "            except:\n",
    "                idx-=1\n",
    "        last_trial_time = tiffheader['movie_start_time'] + datetime.timedelta(seconds = float(tiffheader['description_first_frame']['frameTimestamps_sec']))\n",
    "        \n",
    "        gotit = False\n",
    "        i_ = 0\n",
    "        last_residual_tiff_time = last_trial_time\n",
    "        if 'scanimage_tiff_headers' in bpod_dict['residual_tiff_files'].keys():\n",
    "            while not gotit and np.abs(i_)<len(bpod_dict['residual_tiff_files']['scanimage_tiff_headers']):\n",
    "                i_-=1\n",
    "                try:\n",
    "                    last_residual_tiff_time = bpod_dict['residual_tiff_files']['scanimage_tiff_headers'][i_]['movie_start_time']+ datetime.timedelta(seconds = float(bpod_dict['residual_tiff_files']['scanimage_tiff_headers'][i_]['description_first_frame']['frameTimestamps_sec']))\n",
    "                    gotit = True\n",
    "                except:\n",
    "                    pass\n",
    "        session_end_time = np.max([last_trial_time,last_residual_tiff_time])\n",
    "        \n",
    "        acq_datetime = datetime.datetime.strftime(session_end_time, '%Y-%m-%d %H-%M-%S')\n",
    "        \n",
    "        # locate raw imaging data (no copy required, only folder name)\n",
    "        modality0 = 'ophys'\n",
    "        modality0_source = os.path.join(raw_imaging_path,mouse_id,session)\n",
    "        \n",
    "        \n",
    "        #copy behavior stuff in a folder\n",
    "        modality1 = 'trained_behavior'\n",
    "        modality1_source = Path(os.path.join(CO_save_path,'{}-{}'.format(mouse_id,session),'behavior'))\n",
    "        modality1_source.mkdir(parents=True, exist_ok=True)\n",
    "        copy_command = 'gsutil cp {} {} '.format(behavior_fname,str(modality1_source)+'/'+f\"{session}-bpod_zaber.npy\")\n",
    "        #reply = os.system(copy_command)\n",
    "        if not only_csv_metadata:\n",
    "            subprocess.run(copy_command,shell=True)\n",
    "        bpod_file_names = np.unique(bpod_dict['bpod_file_names'])\n",
    "        \n",
    "        command_list = []\n",
    "        for f in bpod_file_names:\n",
    "            copy_command = 'gsutil -m cp -r {} {} '.format('/home/jupyter/bucket/Data/Behavior/raw/KayvonScope/BCI/experiments/BCI/setups/KayvonScope/sessions/'+f[:-4],\n",
    "                                                     str(modality1_source)+'/')\n",
    "            command_list.append(copy_command)\n",
    "\n",
    "        bash_command = r\" && \".join(command_list)\n",
    "        #os.system(bash_command)\n",
    "        if not only_csv_metadata:\n",
    "            for bash_command in command_list:\n",
    "                subprocess.run(bash_command,shell=True)\n",
    "\n",
    "        \n",
    "        #copy camera data in a single folder under side & bottom\n",
    "        modality2 = 'behavior_videos'\n",
    "        modality2_source = Path(os.path.join(CO_save_path,'{}-{}'.format(mouse_id,session),'behavior_videos'))\n",
    "        modality2_source.mkdir(parents=True, exist_ok=True)\n",
    "        modality2_source_side = Path(os.path.join(CO_save_path,'{}-{}'.format(mouse_id,session),'behavior_videos','side'))\n",
    "        modality2_source_side.mkdir(parents=True, exist_ok=True)\n",
    "        modality2_source_bottom = Path(os.path.join(CO_save_path,'{}-{}'.format(mouse_id,session),'behavior_videos','bottom'))\n",
    "        modality2_source_bottom.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        side_folders = []\n",
    "        bottom_folders = []\n",
    "        \n",
    "        for m in bpod_dict['behavior_movie_name_list']:\n",
    "            if type(m) == np.ndarray:\n",
    "                for movie_name in m:\n",
    "                    if 'side' in movie_name:\n",
    "                        side_folders.append(os.path.join('/home/jupyter/bucket/Data/Behavior_videos/raw/Bergamo-2P-Photostim',*movie_name.split('/')[5:-1]))\n",
    "                    elif 'bottom' in movie_name:\n",
    "                        bottom_folders.append(os.path.join('/home/jupyter/bucket/Data/Behavior_videos/raw/Bergamo-2P-Photostim',*movie_name.split('/')[5:-1]))\n",
    "                    else:\n",
    "                        wtf\n",
    "        side_folders = np.unique(side_folders)\n",
    "        command_list = []\n",
    "        for s in side_folders:\n",
    "            dest  = Path(os.path.join(modality2_source_side,s.split('/')[-1]))\n",
    "            dest.mkdir(parents=True, exist_ok=True)\n",
    "            copy_command = 'gsutil -m rsync {} {} '.format(s,\n",
    "                                                     str(dest)+'/')\n",
    "            command_list.append(copy_command)\n",
    "        bottom_folders = np.unique(bottom_folders)\n",
    "        for b in bottom_folders:\n",
    "            dest  = Path(os.path.join(modality2_source_bottom,b.split('/')[-1]))\n",
    "            dest.mkdir(parents=True, exist_ok=True)\n",
    "            copy_command = 'gsutil -m rsync {} {} '.format(b,\n",
    "                                                     str(dest)+'/')\n",
    "            command_list.append(copy_command)\n",
    "\n",
    "        bash_command = r\" && \".join(command_list)\n",
    "        #os.system(bash_command)\n",
    "        if not only_csv_metadata:\n",
    "            for bash_command in command_list:\n",
    "                subprocess.run(bash_command,shell=True)\n",
    "        #asd\n",
    "        \n",
    "        \n",
    "        upload_dict['platform'].append(platform)\n",
    "        upload_dict['acq_datetime'].append(acq_datetime)\n",
    "        upload_dict['subject_id'].append(subject_id)\n",
    "        upload_dict['s3_bucket'].append(s3_bucket)\n",
    "        upload_dict['modality0'].append(modality0)\n",
    "        upload_dict['modality0.source'].append(str(modality0_source))\n",
    "        upload_dict['modality1'].append(modality1)\n",
    "        upload_dict['modality1.source'].append(str(modality1_source))\n",
    "        upload_dict['modality2'].append(modality2)\n",
    "        upload_dict['modality2.source'].append(str(modality2_source))\n",
    "        upload_dict['version'].append(version)\n",
    "        \n",
    "        # save this stuff\n",
    "        output_df = pd.DataFrame.from_dict(upload_dict)\n",
    "        for r_ in output_df.iterrows():\n",
    "            pass # get the last row\n",
    "        r_dict = r_[1].to_dict()\n",
    "        import json\n",
    "        with open(upload_json_location, 'w') as f:\n",
    "            json.dump(r_dict, f)\n",
    "        \n",
    "# output_df = pd.DataFrame.from_dict(upload_dict)\n",
    "# output_df.to_csv(os.path.join(CO_save_path,'uplpoad_job_ALL.csv'))\n",
    "df_error = pd.DataFrame(np.asarray([skipped_directories,skip_reason]).T,columns = ['dir_name','error'])\n",
    "df_error.to_csv(os.path.join(CO_save_path,'not_included_folders.csv'))\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e3bb62-ef70-42e6-80a8-97f6799836da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK1 - go through problematic sessions and check what's the problem..\n",
    "\n",
    "df_error = pd.read_csv(os.path.join(CO_save_path,'not_included_folders.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9e56c6f-34f6-415c-b931-9aa02f40b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for error_type in df_error['error'].unique():\n",
    "    errors_now = df_error.loc[df_error['error']==error_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c61039ba-5102-4d64-b1ef-ef8ae7e547bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/jupyter/bucket/Data/Calcium_imaging/raw/Bergamo-2P-Photostim/BCI_43/040323',\n",
       "       '/home/jupyter/bucket/Data/Calcium_imaging/raw/Bergamo-2P-Photostim/BCI_67/092523',\n",
       "       '/home/jupyter/bucket/Data/Calcium_imaging/raw/Bergamo-2P-Photostim/BCI_69/012624'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_now['dir_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4347196-a79a-45a1-8eed-cadd94a9beb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BCI_29-041822', '2022-04-21 13-28-09', datetime.timedelta(days=-3)]\n"
     ]
    }
   ],
   "source": [
    "#Task2 : a single session has an extra z-stack that messes up session date \n",
    "sessions_saved = os.listdir(CO_save_path)\n",
    "for dir_now in sessions_saved:\n",
    "    if '.' in dir_now:\n",
    "        continue\n",
    "    filesindir = os.listdir(os.path.join(CO_save_path,dir_now))\n",
    "    try:\n",
    "        with open(os.path.join(CO_save_path,dir_now,'uppload_job_part.json'), 'r') as f:\n",
    "            upload_json = json.load(f)\n",
    "    except:\n",
    "        continue\n",
    "    dt = (datetime.datetime.strptime(dir_now[-6:],'%m%d%y')-datetime.datetime.strptime(upload_json['acq_datetime'][:upload_json['acq_datetime'].find(' ')],'%Y-%m-%d'))\n",
    "    if np.abs(dt.days)>0:\n",
    "        print([dir_now,upload_json['acq_datetime'],dt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48b92e87-c1ba-45f1-b545-783bec993b9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupload_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macq_datetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "datetime.datetime.strptime(upload_json['acq_datetime'],'%YYYY-%MM-%DD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "562f86f4-7d51-4283-90ac-303ef987a69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-03'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b6f69dd-6db9-47b3-93f7-c5de1d6dd06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bafd842-9e5c-4e71-bce3-d8130baa6bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.days"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "bci_with_suite2p",
   "name": "common-cpu.m92",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m92"
  },
  "kernelspec": {
   "display_name": "bci_with_suite2p",
   "language": "python",
   "name": "bci_with_suite2p"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
